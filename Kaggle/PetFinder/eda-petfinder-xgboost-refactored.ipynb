{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c25c19f9474215497d939344de1a729fd43878ea"
   },
   "source": [
    "## Table of contents\n",
    "\n",
    "* Purpose\n",
    "* Dataset\n",
    "    * General properties\n",
    "    * Missing Values\n",
    "    * Numerical attributes and outliers\n",
    "    * Categorical attributes and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4119b4e6f0e29b82480871ddf05cd33400f99e0"
   },
   "source": [
    "## Purpose\n",
    "In this competition you will predict the speed at which a pet is adopted, based on the petâ€™s listing on PetFinder. Sometimes a profile represents a group of pets. In this case, the speed of adoption is determined by the speed at which all of the pets are adopted. The data included text, tabular, and image data. See below for details. \n",
    "This is a Kernels-only competition. At the end of the competition, test data will be replaced in their entirety with new data of approximately the same size, and your kernels will be rerun on the new data.\n",
    "\n",
    "**File descriptions**\n",
    "* train.csv - Tabular/text data for the training set\n",
    "* test.csv - Tabular/text data for the test set\n",
    "* sample_submission.csv - A sample submission file in the correct format\n",
    "* breed_labels.csv - Contains Type, and BreedName for each BreedID. Type 1 is dog, 2 is cat.\n",
    "* color_labels.csv - Contains ColorName for each ColorID\n",
    "* state_labels.csv - Contains StateName for each StateID\n",
    "\n",
    "**Data Fields**\n",
    "* PetID - Unique hash ID of pet profile\n",
    "* AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n",
    "* Type - Type of animal (1 = Dog, 2 = Cat)\n",
    "* Name - Name of pet (Empty if not named)\n",
    "* Age - Age of pet when listed, in months\n",
    "* Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "* Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n",
    "* Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n",
    "* Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n",
    "* Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n",
    "* Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n",
    "* MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n",
    "* FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n",
    "* Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "* Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "* Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "* Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n",
    "* Quantity - Number of pets represented in profile\n",
    "* Fee - Adoption fee (0 = Free)\n",
    "* State - State location in Malaysia (Refer to StateLabels dictionary)\n",
    "* RescuerID - Unique hash ID of rescuer\n",
    "* VideoAmt - Total uploaded videos for this pet\n",
    "* PhotoAmt - Total uploaded photos for this pet\n",
    "* Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n",
    "\n",
    "**AdoptionSpeed**\n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way: \n",
    "\n",
    "0 - Pet was adopted on the same day as it was listed. \n",
    "\n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed. \n",
    "\n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed. \n",
    "\n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n",
    "\n",
    "4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images', 'breed_labels.csv', '.DS_Store', 'petfinder-adoption-prediction', 'petfinder-adoption-prediction.zip', 'single-xgboost-model.ipynb', 'train_metadata', 'test.csv', 'color_labels.csv', 'test_sentiment', 'test_metadata', 'eda-petfinder.ipynb', 'train_sentiment', 'densenet-keras', 'train.csv', '.ipynb_checkpoints', 'eda-petfinder-xgboost-refactored.ipynb', 'train_images', 'state_labels.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import json, glob, cv2\n",
    "from math import copysign, log10\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier, FeaturesData, Pool\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "\n",
    "palette = sns.color_palette(\"RdBu_r\", 7)\n",
    "sns.set()\n",
    "sns.set_palette(palette)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4dacd33535aa1b6dbcba7faa207fd5759b96726"
   },
   "source": [
    "## **General properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "215071cd9755c5a4989981e42ea82b5a4f94c8f4"
   },
   "outputs": [],
   "source": [
    "# local\n",
    "trainPath = './train.csv'\n",
    "testPath = './test.csv'\n",
    "trainSentimentPath = './train_sentiment/'\n",
    "testSentimentPath = './test_sentiment/'\n",
    "trainMetadataPath = './train_metadata/'\n",
    "testMetadataPath = './test_metadata/'\n",
    "trainImagePath = './train_images/'\n",
    "testImagePath = './test_images/'\n",
    "breedPath = './breed_labels.csv'\n",
    "colorPath = './color_labels.csv'\n",
    "statePath = 'state_labels.csv'\n",
    "# kaggle kernel\n",
    "# trainPath = '../input/petfinder-adoption-prediction/train/train.csv'\n",
    "# testPath = '../input/petfinder-adoption-prediction/test/test.csv'\n",
    "# trainSentimentPath = '../input/petfinder-adoption-prediction/train_sentiment/'\n",
    "# testSentimentPath = '../input/petfinder-adoption-prediction/test_sentiment/'\n",
    "# trainMetadataPath = '../input/petfinder-adoption-prediction/train_metadata/'\n",
    "# testMetadataPath = '../input/petfinder-adoption-prediction/test_metadata/'\n",
    "# trainImagePath = '../input/petfinder-adoption-prediction/train_images/'\n",
    "# testImagePath = '../input/petfinder-adoption-prediction/test_images/'\n",
    "# breedPath = '../input/petfinder-adoption-prediction/breed_labels.csv'\n",
    "# colorPath = '../input/petfinder-adoption-prediction/color_labels.csv'\n",
    "# statePath = '../input/petfinder-adoption-prediction/state_labels.csv'\n",
    "# trainPrecomputedPath = '../input/precomputedfeaturespetfinder/train_precomputed.csv'\n",
    "# testPrecomputedPath = '../input/precomputedfeaturespetfinder/test_precomputed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "6514f01967b000526fdeef119424bc266de4096c"
   },
   "outputs": [],
   "source": [
    "categoricalFeatures = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n",
    "                       'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "                       'Health', 'State', 'RescuerID', 'AdoptionSpeed']\n",
    "numericalFeatures = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "10e390ae4e590396e9026b6b5aa5bc9ced8659fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14993 entries, 0 to 14992\n",
      "Data columns (total 24 columns):\n",
      "Type             14993 non-null int64\n",
      "Name             13736 non-null object\n",
      "Age              14993 non-null int64\n",
      "Breed1           14993 non-null int64\n",
      "Breed2           14993 non-null int64\n",
      "Gender           14993 non-null int64\n",
      "Color1           14993 non-null int64\n",
      "Color2           14993 non-null int64\n",
      "Color3           14993 non-null int64\n",
      "MaturitySize     14993 non-null int64\n",
      "FurLength        14993 non-null int64\n",
      "Vaccinated       14993 non-null int64\n",
      "Dewormed         14993 non-null int64\n",
      "Sterilized       14993 non-null int64\n",
      "Health           14993 non-null int64\n",
      "Quantity         14993 non-null int64\n",
      "Fee              14993 non-null int64\n",
      "State            14993 non-null int64\n",
      "RescuerID        14993 non-null object\n",
      "VideoAmt         14993 non-null int64\n",
      "Description      14981 non-null object\n",
      "PetID            14993 non-null object\n",
      "PhotoAmt         14993 non-null float64\n",
      "AdoptionSpeed    14993 non-null int64\n",
      "dtypes: float64(1), int64(19), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#  local\n",
    "train = pd.read_csv(trainPath)\n",
    "test = pd.read_csv(testPath)\n",
    "# kaggle kernel\n",
    "# train = pd.read_csv('../input/train/train.csv')\n",
    "# test = pd.read_csv('../input/test/test.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEGIN XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2]\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "import keras.backend as K\n",
    "\n",
    "# denseNetPath = '../input/densenet-keras/DenseNet-BC-121-32-no-top.h5'\n",
    "denseNetPath = './densenet-keras/DenseNet-BC-121-32-no-top.h5'\n",
    "\n",
    "inp = Input((256,256,3))\n",
    "backbone = DenseNet121(input_tensor = inp, \n",
    "                       weights=denseNetPath,\n",
    "                       include_top = False)\n",
    "x = backbone.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "x = AveragePooling1D(4)(x)\n",
    "out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "m = Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = train['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(trainImagePath, pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "train_feats.columns = [f'pic_{i}' for i in range(train_feats.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = test['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(testImagePath, pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "test_feats.columns = [f'pic_{i}' for i in range(test_feats.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.concat([train, test], axis=0, ignore_index=True, sort=False)[['PetID']]\n",
    "all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 32\n",
    "svd_ = TruncatedSVD(n_components=n_components, random_state=1337)\n",
    "\n",
    "features_df = pd.concat([train_feats, test_feats], axis=0)\n",
    "features = features_df[[f'pic_{i}' for i in range(256)]].values\n",
    "\n",
    "svd_col = svd_.fit_transform(features)\n",
    "svd_col = pd.DataFrame(svd_col)\n",
    "svd_col = svd_col.add_prefix('IMG_SVD_')\n",
    "\n",
    "img_features = pd.concat([all_ids, svd_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About metadata and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_breed = pd.read_csv(breedPath)\n",
    "labels_state = pd.read_csv(colorPath)\n",
    "labels_color = pd.read_csv(statePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files = sorted(glob.glob(trainImagePath + '*.jpg'))\n",
    "train_metadata_files = sorted(glob.glob(trainMetadataPath + '*.json'))\n",
    "train_sentiment_files = sorted(glob.glob(trainSentimentPath + '*.json'))\n",
    "\n",
    "print(f'num of train images files: {len(train_image_files)}')\n",
    "print(f'num of train metadata files: {len(train_metadata_files)}')\n",
    "print(f'num of train sentiment files: {len(train_sentiment_files)}')\n",
    "\n",
    "\n",
    "test_image_files = sorted(glob.glob(testImagePath + '*.jpg'))\n",
    "test_metadata_files = sorted(glob.glob(testMetadataPath + '*.json'))\n",
    "test_sentiment_files = sorted(glob.glob(testSentimentPath + '*.json'))\n",
    "\n",
    "print(f'num of test images files: {len(test_image_files)}')\n",
    "print(f'num of test metadata files: {len(test_metadata_files)}')\n",
    "print(f'num of test sentiment files: {len(test_sentiment_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_metadata_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5c946eb22ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Metadata:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_df_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PetID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_df_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metadata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_df_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'metadata_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_metadata_pets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_metadata_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Images:\n",
    "train_df_ids = train[['PetID']]\n",
    "print(train_df_ids.shape)\n",
    "\n",
    "# Metadata:\n",
    "train_df_ids = train[['PetID']]\n",
    "train_df_metadata = pd.DataFrame(train_metadata_files)\n",
    "train_df_metadata.columns = ['metadata_filename']\n",
    "train_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "train_df_metadata = train_df_metadata.assign(PetID=train_metadata_pets)\n",
    "print(len(train_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(train_metadata_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with metadata: {pets_with_metadatas / train_df_ids.shape[0]:.3f}')\n",
    "\n",
    "# Sentiment:\n",
    "train_df_ids = train[['PetID']]\n",
    "train_df_sentiment = pd.DataFrame(train_sentiment_files)\n",
    "train_df_sentiment.columns = ['sentiment_filename']\n",
    "train_sentiment_pets = train_df_sentiment['sentiment_filename'].apply(lambda x: x.split(split_char)[-1].split('.')[0])\n",
    "train_df_sentiment = train_df_sentiment.assign(PetID=train_sentiment_pets)\n",
    "print(len(train_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(train_sentiment_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with sentiment: {pets_with_sentiments / train_df_ids.shape[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images:\n",
    "test_df_ids = test[['PetID']]\n",
    "print(test_df_ids.shape)\n",
    "\n",
    "# Metadata:\n",
    "test_df_metadata = pd.DataFrame(test_metadata_files)\n",
    "test_df_metadata.columns = ['metadata_filename']\n",
    "test_metadata_pets = test_df_metadata['metadata_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "test_df_metadata = test_df_metadata.assign(PetID=test_metadata_pets)\n",
    "print(len(test_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(test_metadata_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with metadata: {pets_with_metadatas / test_df_ids.shape[0]:.3f}')\n",
    "\n",
    "# Sentiment:\n",
    "test_df_sentiment = pd.DataFrame(test_sentiment_files)\n",
    "test_df_sentiment.columns = ['sentiment_filename']\n",
    "test_sentiment_pets = test_df_sentiment['sentiment_filename'].apply(lambda x: x.split(split_char)[-1].split('.')[0])\n",
    "test_df_sentiment = test_df_sentiment.assign(PetID=test_sentiment_pets)\n",
    "print(len(test_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(test_sentiment_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with sentiment: {pets_with_sentiments / test_df_ids.shape[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderParser(object):\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.sentence_sep = ' '\n",
    "        \n",
    "        self.extract_sentiment_text = False\n",
    "    \n",
    "    def open_json_file(self, filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            json_file = json.load(f)\n",
    "        return json_file\n",
    "        \n",
    "    def parse_sentiment_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse sentiment file. Output DF with sentiment features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_sentiment = file['documentSentiment']\n",
    "        file_entities = [x['name'] for x in file['entities']]\n",
    "        file_entities = self.sentence_sep.join(file_entities)\n",
    "        \n",
    "        file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n",
    "        \n",
    "        file_sentences_sentiment = pd.DataFrame.from_dict(\n",
    "            file_sentences_sentiment, orient='columns')\n",
    "        file_sentences_sentiment_df = pd.DataFrame(\n",
    "            {\n",
    "                'magnitude_sum': file_sentences_sentiment['magnitude'].sum(axis=0),\n",
    "                'score_sum': file_sentences_sentiment['score'].sum(axis=0),\n",
    "                'magnitude_mean': file_sentences_sentiment['magnitude'].mean(axis=0),\n",
    "                'score_mean': file_sentences_sentiment['score'].mean(axis=0),\n",
    "                'magnitude_var': file_sentences_sentiment['magnitude'].var(axis=0),\n",
    "                'score_var': file_sentences_sentiment['score'].var(axis=0),\n",
    "            }, index=[0]\n",
    "        )\n",
    "        \n",
    "        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n",
    "        df_sentiment = pd.concat([df_sentiment, file_sentences_sentiment_df], axis=1)\n",
    "            \n",
    "        df_sentiment['entities'] = file_entities\n",
    "        df_sentiment = df_sentiment.add_prefix('sentiment_')\n",
    "        \n",
    "        return df_sentiment\n",
    "    \n",
    "    def parse_metadata_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse metadata file. Output DF with metadata features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_keys = list(file.keys())\n",
    "        \n",
    "        if 'labelAnnotations' in file_keys:\n",
    "            file_annots = file['labelAnnotations']\n",
    "            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "            file_top_desc = [x['description'] for x in file_annots]\n",
    "        else:\n",
    "            file_top_score = np.nan\n",
    "            file_top_desc = ['']\n",
    "        \n",
    "        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        file_crops = file['cropHintsAnnotation']['cropHints']\n",
    "\n",
    "        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n",
    "\n",
    "        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "        \n",
    "        if 'importanceFraction' in file_crops[0].keys():\n",
    "            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "        else:\n",
    "            file_crop_importance = np.nan\n",
    "\n",
    "        df_metadata = {\n",
    "            'annots_score': file_top_score,\n",
    "            'color_score': file_color_score,\n",
    "            'color_pixelfrac': file_color_pixelfrac,\n",
    "            'crop_conf': file_crop_conf,\n",
    "            'crop_importance': file_crop_importance,\n",
    "            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n",
    "        }\n",
    "        \n",
    "        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n",
    "        df_metadata = df_metadata.add_prefix('metadata_')\n",
    "        \n",
    "        return df_metadata\n",
    "    \n",
    "\n",
    "def extract_additional_features(pet_id, mode='train'):\n",
    "    \n",
    "    sentiment_filename = f'./{mode}_sentiment/{pet_id}.json'\n",
    "    try:\n",
    "        sentiment_file = pet_parser.open_json_file(sentiment_filename)\n",
    "        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n",
    "        df_sentiment['PetID'] = pet_id\n",
    "    except FileNotFoundError:\n",
    "        df_sentiment = []\n",
    "\n",
    "    dfs_metadata = []\n",
    "    metadata_filenames = sorted(glob.glob(f'./{mode}_metadata/{pet_id}*.json'))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        for f in metadata_filenames:\n",
    "            metadata_file = pet_parser.open_json_file(f)\n",
    "            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n",
    "            df_metadata['PetID'] = pet_id\n",
    "            dfs_metadata.append(df_metadata)\n",
    "        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n",
    "    dfs = [df_sentiment, dfs_metadata]\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "pet_parser = PetFinderParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "train_pet_ids = train.PetID.unique()\n",
    "test_pet_ids = test.PetID.unique()\n",
    "\n",
    "if debug:\n",
    "    train_pet_ids = train_pet_ids[:1000]\n",
    "    test_pet_ids = test_pet_ids[:500]\n",
    "\n",
    "\n",
    "dfs_train = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='train') for i in train_pet_ids)\n",
    "\n",
    "train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n",
    "train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n",
    "train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(train_dfs_sentiment.shape, train_dfs_metadata.shape)\n",
    "\n",
    "\n",
    "dfs_test = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n",
    "\n",
    "test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n",
    "test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n",
    "test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(test_dfs_sentiment.shape, test_dfs_metadata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group extracted features by PetID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = ['sum', 'mean', 'var']\n",
    "sent_agg = ['sum']\n",
    "\n",
    "\n",
    "# Train\n",
    "train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "train_metadata_desc = train_metadata_desc.reset_index()\n",
    "train_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = train_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in train_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n",
    "train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}' for c in train_metadata_gr.columns.tolist()])\n",
    "train_metadata_gr = train_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "train_sentiment_desc = train_sentiment_desc.reset_index()\n",
    "train_sentiment_desc[\n",
    "    'sentiment_entities'] = train_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in train_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n",
    "train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n",
    "train_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in train_sentiment_gr.columns.tolist()])\n",
    "train_sentiment_gr = train_sentiment_gr.reset_index()\n",
    "\n",
    "\n",
    "# Test\n",
    "test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "test_metadata_desc = test_metadata_desc.reset_index()\n",
    "test_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = test_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in test_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n",
    "test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}' for c in test_metadata_gr.columns.tolist()])\n",
    "test_metadata_gr = test_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "test_sentiment_desc = test_sentiment_desc.reset_index()\n",
    "test_sentiment_desc[\n",
    "    'sentiment_entities'] = test_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in test_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n",
    "test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n",
    "test_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in test_sentiment_gr.columns.tolist()])\n",
    "test_sentiment_gr = test_sentiment_gr.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge processed DFs with base train/test DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train merges:\n",
    "train_proc = train.copy()\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_desc, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "# Test merges:\n",
    "test_proc = test.copy()\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_desc, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n",
    "assert train_proc.shape[0] == train.shape[0]\n",
    "assert test_proc.shape[0] == test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_breed_main = train_proc[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "train_breed_main = train_breed_main.iloc[:, 2:]\n",
    "train_breed_main = train_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "train_breed_second = train_proc[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "train_breed_second = train_breed_second.iloc[:, 2:]\n",
    "train_breed_second = train_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "\n",
    "train_proc = pd.concat(\n",
    "    [train_proc, train_breed_main, train_breed_second], axis=1)\n",
    "\n",
    "\n",
    "test_breed_main = test_proc[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "test_breed_main = test_breed_main.iloc[:, 2:]\n",
    "test_breed_main = test_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "test_breed_second = test_proc[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "test_breed_second = test_breed_second.iloc[:, 2:]\n",
    "test_breed_second = test_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "\n",
    "test_proc = pd.concat(\n",
    "    [test_proc, test_breed_main, test_breed_second], axis=1)\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.copy()\n",
    "\n",
    "text_columns = ['Description', 'metadata_annots_top_desc', 'sentiment_entities']\n",
    "categorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n",
    "\n",
    "to_drop_columns = ['PetID', 'Name', 'RescuerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "rescuer_count.columns = ['RescuerID', 'RescuerID_COUNT']\n",
    "\n",
    "X_temp = X_temp.merge(rescuer_count, how='left', on='RescuerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_columns:\n",
    "    X_temp.loc[:, i] = pd.factorize(X_temp.loc[:, i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = X_temp[text_columns]\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_text.loc[:, i] = X_text.loc[:, i].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp['Length_Description'] = X_text['Description'].map(len)\n",
    "X_temp['Length_metadata_annots_top_desc'] = X_text['metadata_annots_top_desc'].map(len)\n",
    "X_temp['Lengths_sentiment_entities'] = X_text['sentiment_entities'].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 16\n",
    "text_features = []\n",
    "\n",
    "# Generate text features:\n",
    "for i in X_text.columns:\n",
    "    \n",
    "    # Initialize decomposition methods:\n",
    "    print(f'generating features from: {i}')\n",
    "    tfv = TfidfVectorizer(min_df=2,  max_features=None,\n",
    "                          strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                          ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "    svd_ = TruncatedSVD(\n",
    "        n_components=n_components, random_state=1337)\n",
    "    \n",
    "    tfidf_col = tfv.fit_transform(X_text.loc[:, i].values)\n",
    "    \n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix('TFIDF_{}_'.format(i))\n",
    "    \n",
    "    text_features.append(svd_col)\n",
    "    \n",
    "text_features = pd.concat(text_features, axis=1)\n",
    "\n",
    "X_temp = pd.concat([X_temp, text_features], axis=1)\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_temp = X_temp.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_temp.merge(img_features, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add image_size features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "train_df_ids = train[['PetID']]\n",
    "test_df_ids = test[['PetID']]\n",
    "\n",
    "train_df_imgs = pd.DataFrame(train_image_files)\n",
    "train_df_imgs.columns = ['image_filename']\n",
    "train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "test_df_imgs = pd.DataFrame(test_image_files)\n",
    "test_df_imgs.columns = ['image_filename']\n",
    "test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n",
    "test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n",
    "\n",
    "def getSize(filename):\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(filename):\n",
    "    img_size = Image.open(filename).size\n",
    "    return img_size \n",
    "\n",
    "train_df_imgs['image_size'] = train_df_imgs['image_filename'].apply(getSize)\n",
    "train_df_imgs['temp_size'] = train_df_imgs['image_filename'].apply(getDimensions)\n",
    "train_df_imgs['width'] = train_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "train_df_imgs['height'] = train_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "train_df_imgs = train_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "test_df_imgs['image_size'] = test_df_imgs['image_filename'].apply(getSize)\n",
    "test_df_imgs['temp_size'] = test_df_imgs['image_filename'].apply(getDimensions)\n",
    "test_df_imgs['width'] = test_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "test_df_imgs['height'] = test_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "test_df_imgs = test_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "aggs = {\n",
    "    'image_size': ['sum', 'mean', 'var'],\n",
    "    'width': ['sum', 'mean', 'var'],\n",
    "    'height': ['sum', 'mean', 'var'],\n",
    "}\n",
    "\n",
    "agg_train_imgs = train_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_train_imgs.columns = new_columns\n",
    "agg_train_imgs = agg_train_imgs.reset_index()\n",
    "\n",
    "agg_test_imgs = test_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_test_imgs.columns = new_columns\n",
    "agg_test_imgs = agg_test_imgs.reset_index()\n",
    "\n",
    "agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_temp.merge(agg_imgs, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop ID, name and rescuerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_temp = X_temp.drop(to_drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "X_test = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "\n",
    "# X_test = X_test.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "assert X_train.shape[0] == train.shape[0]\n",
    "assert X_test.shape[0] == test.shape[0]\n",
    "\n",
    "train_cols = X_train.columns.tolist()\n",
    "# train_cols.remove('AdoptionSpeed')\n",
    "\n",
    "test_cols = X_test.columns.tolist()\n",
    "\n",
    "assert np.all(train_cols == test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final train and test (with NA)\n",
    "X_train.to_csv('train_precomputed.csv', index=False)\n",
    "X_test.to_csv('test_precomputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_null = X_train.fillna(-1)\n",
    "X_test_non_null = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_null.isnull().any().any(), X_test_non_null.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_null.shape, X_test_non_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "\n",
    "\n",
    "# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OptimizeRounder from [OptimizedRounder() - Improved](https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "    \n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return -cohen_kappa_score(y, preds, weights='quadratic')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "    \n",
    "    def predict(self, X, coef):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return preds\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccac125844cb036137312e9d55a48f23597414c0"
   },
   "source": [
    "Let's replace the ids from the categorical features for human readable values to make our analysis easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56ca3a0d329a67322321b719e089553cfc1e8f2a"
   },
   "outputs": [],
   "source": [
    "breedDf = pd.read_csv(breedPath)\n",
    "breedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "193efbf6f9d96123d825c8fe5fc801cc4207c28e"
   },
   "outputs": [],
   "source": [
    "colorDf = pd.read_csv(colorPath)\n",
    "colorDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d0fda2464fcc2f6e9b7fd760d393709aa24fbb4"
   },
   "outputs": [],
   "source": [
    "stateDf = pd.read_csv(statePath)\n",
    "stateDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04d9f0388fb22e56e52fb662d89fbe9563025e7f"
   },
   "outputs": [],
   "source": [
    "def cleanTransformDataset(dataset, categoricalFeatures):\n",
    "    breedDf2 = breedDf.set_index('BreedID')\n",
    "    idx = breedDf2.to_dict()\n",
    "    dataset.Breed1 = dataset.Breed1.map(idx['BreedName'])\n",
    "    dataset.Breed2 = dataset.Breed2.map(idx['BreedName'])\n",
    "    \n",
    "    colorDf2 = colorDf.set_index('ColorID')\n",
    "    idx = colorDf2.to_dict()\n",
    "    dataset.Color1 = dataset.Color1.map(idx['ColorName'])\n",
    "    dataset.Color2 = dataset.Color2.map(idx['ColorName'])\n",
    "    dataset.Color3 = dataset.Color3.map(idx['ColorName'])\n",
    "    \n",
    "    stateDf2 = stateDf.set_index('StateID')\n",
    "    idx = stateDf2.to_dict()\n",
    "    dataset.State = dataset.State.map(idx['StateName'])\n",
    "    \n",
    "    # 1 = Dog, 2 = Cat\n",
    "    dataset.Type = dataset.Type.map({1: 'Dog', 2: 'Cat'})\n",
    "    # 1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets\n",
    "    dataset.Gender = dataset.Gender.map({1: 'Male', 2: 'Female', 3: 'Mixed'})\n",
    "    # 1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified\n",
    "    dataset.MaturitySize = dataset.MaturitySize.map({1: 'Small', 2: 'Medium', 3: 'Large', 4: 'Extra Large', 0: 'Not Specified'})\n",
    "    # 1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified\n",
    "    dataset.FurLength = dataset.FurLength.map({1: 'Short', 2: 'Medium', 3: 'Long', 0: 'Not Specified'})\n",
    "    # 1 = Yes, 2 = No, 3 = Not Sure\n",
    "    dataset.Vaccinated = dataset.Vaccinated.map({1: 'Yes', 2: 'No', 3: 'Not Sure'})\n",
    "    # 1 = Yes, 2 = No, 3 = Not Sure\n",
    "    dataset.Dewormed = dataset.Dewormed.map({1: 'Yes', 2: 'No', 3: 'Not Sure'})\n",
    "    # 1 = Yes, 2 = No, 3 = Not Sure\n",
    "    dataset.Sterilized = dataset.Sterilized.map({1: 'Yes', 2: 'No', 3: 'Not Sure'})\n",
    "    # 1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified\n",
    "    dataset.Health = dataset.Health.map({1: 'Healthy', 2: 'Minor Injury', 3: 'Serious Injury', 0: 'Not Specified'})\n",
    "    # transform to categorical\n",
    "    dataset[categoricalFeatures] = dataset[categoricalFeatures].astype('category')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "018e4f330f89c8dd579747a5a5434b26fbd35ac4"
   },
   "outputs": [],
   "source": [
    "train = cleanTransformDataset(train, categoricalFeatures)\n",
    "test = cleanTransformDataset(test, list(set(categoricalFeatures) - set(['AdoptionSpeed'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "57701fa79c385560fb81f70f67061756f15880f6"
   },
   "source": [
    "### Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3bf4922b1cfd1670266a92b8e0a845d44f963ec"
   },
   "outputs": [],
   "source": [
    "def extraFeatures(train):\n",
    "    # Color (Create a Flag pet has 1 color, 2 colors, 3 colors)\n",
    "    train['L_Color1'] = (pd.isnull(train['Color3']) & pd.isnull(train['Color2']) & pd.notnull(train['Color1'])).astype(int)\n",
    "    train['L_Color2'] = (pd.isnull(train['Color3']) & pd.notnull(train['Color2']) & pd.notnull(train['Color1'])).astype(int)\n",
    "    train['L_Color3'] = (pd.notnull(train['Color3']) & pd.notnull(train['Color2']) & pd.notnull(train['Color1'])).astype(int)\n",
    "\n",
    "    # Breed (create a flag if the pet has 1 breed or 2)\n",
    "    train['L_Breed1'] = (pd.isnull(train['Breed2']) & pd.notnull(train['Breed1'])).astype(int)\n",
    "    train['L_Breed2'] = (pd.notnull(train['Breed2']) & pd.notnull(train['Breed1'])).astype(int)\n",
    "\n",
    "    #Name (create a flag if the name is missing, with less than two letters)\n",
    "    train['Name_Length']= train['Name'].str.len()\n",
    "    train['L_Name_missing'] = (pd.isnull(train['Name'])).astype(int)\n",
    "\n",
    "    # Breed create columns\n",
    "    train['L_Breed1_Siamese'] =(train['Breed1']=='Siamese').astype(int)\n",
    "    train['L_Breed1_Persian']=(train['Breed1']=='Persian').astype(int)\n",
    "    train['L_Breed1_Labrador_Retriever']=(train['Breed1']=='Labrador Retriever').astype(int)\n",
    "    train['L_Breed1_Terrier']=(train['Breed1']=='Terrier').astype(int)\n",
    "    train['L_Breed1_Golden_Retriever ']=(train['Breed1']=='Golden Retriever').astype(int)\n",
    "\n",
    "    #Description \n",
    "    train['Description_Length']=train['Description'].str.len() \n",
    "\n",
    "    # Fee Amount\n",
    "    train['L_Fee_Free'] =  (train['Fee']==0).astype(int)\n",
    "\n",
    "    #Add the Number of Pets per Rescuer \n",
    "    pets_total = train.groupby(['RescuerID']).size().reset_index(name='N_pets_total')\n",
    "    train= pd.merge(train, pets_total, left_on='RescuerID', right_on='RescuerID', how='inner')\n",
    "    train.count()\n",
    "\n",
    "    # No photo\n",
    "    train['L_NoPhoto'] =  (train['PhotoAmt']==0).astype(int)\n",
    "\n",
    "    #No Video\n",
    "    train['L_NoVideo'] =  (train['VideoAmt']==0).astype(int)\n",
    "\n",
    "    #Log Age \n",
    "    train['Log_Age']= np.log(train.Age + 1) \n",
    "\n",
    "    #Negative Score \n",
    "    train['L_scoreneg'] =  (train['sentiment_document_score']<0).astype(int)\n",
    "\n",
    "    #Quantity Amount >5\n",
    "    train.loc[train['Quantity'] > 5, 'Quantity'] = 5\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2994a6982f70c938b3ac6bcbbb743bb272927b1"
   },
   "outputs": [],
   "source": [
    "train = extraFeatures(train)\n",
    "test = extraFeatures(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2c7a105c8ecdf23f1b7dfa024b3a207ddd4b51e"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf93492d31e185c428551707ce7f8f1e4b03e049"
   },
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numericalFeatures = list(train.select_dtypes(include=numerics).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc5555696b590335e031975cd63638c2bd8bc2ff"
   },
   "outputs": [],
   "source": [
    "trainPrecomputed = pd.read_csv(trainPrecomputedPath)\n",
    "testPrecomputed = pd.read_csv(testPrecomputedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53100e880276b762afd1a2e7dd7c5f1a434a80f4"
   },
   "outputs": [],
   "source": [
    "trainPrecomputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bafe3041781e88be1ef6dbcaeed8b64b03997416"
   },
   "outputs": [],
   "source": [
    "testPrecomputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8aeb9c2cf52a57740b5718c239f1b988e640e11e"
   },
   "source": [
    "Findings:\n",
    "* `age` has a max value too high, need to be investigated. 255 months is 21 years is hard to believe that this is accurate.\n",
    "*  need to join `breed` and `color` values from other dataset\n",
    "* categorical features: `Type`, `Breed1`, `Breed2`, `Gender`, `Color1`, `Color2`, `Color3`, `MaturitySize`, `FurLength`, `Vaccinated`, `Dewormed`, `Sterilized`, `Health`, `Fee`, `State`, `RescuerID`, `AdoptionSpeed`\n",
    "* unstructured text features: `Description`\n",
    "* numerical features: `Age`, `Quantity`, `VideoAmt`, `PhotoAmt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dc54f773660f4641f8b5be83f9c0b4d525d5d21"
   },
   "source": [
    "## **Missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "346c7d0dd752d4d6a730a3d0d0c170bfec9d82c8"
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51c690a3223e80b4dc5d7d4e3abf4b63b61dc751"
   },
   "outputs": [],
   "source": [
    "msno.matrix(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbd8be2214a7738d2abf17ba825320bc1d2d672a"
   },
   "source": [
    "## **Numerical attributes and outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a63997be9580fe6b913fb8f5374511adbd3a88ca"
   },
   "source": [
    "#### **AdoptionSpeed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d421de6840626e267d61684122ec944d651c1bf"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"AdoptionSpeed\", kind=\"count\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c47c10ba2165af427452ec1d513809c5f1a90bbb"
   },
   "source": [
    "Findings: \n",
    "* We have an unbalanced class, that could be a problem for some models.\n",
    "* The probability of being adopted increases in the first month and then declines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82147e82f34984a765365aa641c26415c3629a83"
   },
   "source": [
    "#### **Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aed66cca3fe78a4aed974242618293a2551d9375"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,8))\n",
    "sns.boxplot(y=train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6125f411d4d5625f608fc3ceb7447b9eba3fb9fe"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.distplot(train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9866e3bc6dc983b17201cca59808860fbf32683"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"AdoptionSpeed\", y=\"Age\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14c1475de77a6dc3d37f8a0e043c2735ff5e10de"
   },
   "outputs": [],
   "source": [
    "sns.catplot(y=\"AdoptionSpeed\", x=\"Age\", data=train, orient=\"h\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e1fd22520ea95325973a4065354d6c4b9cee998"
   },
   "source": [
    "Let's get a better visual look between age intervals and the adoption speed.\n",
    "Based on our distribution we can divide our age in 4 categories: 0-1 year, 1-2 years, 2-4 years, 4-10 years and >10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e895cd755b8a17551619c16347cd17bf5cc2058"
   },
   "outputs": [],
   "source": [
    "train['AgeInterval'] = pd.Series(['0-3', '3-6', '6-12', '12-24', '24-48', '48-120', '>120'], dtype='category')\n",
    "train.loc[(train['Age'] >= 0) & (train['Age'] <= 3),'AgeInterval'] = '0-3'\n",
    "train.loc[(train['Age'] > 3) & (train['Age'] <= 6),'AgeInterval'] = '3-6'\n",
    "train.loc[(train['Age'] > 6) & (train['Age'] <= 12),'AgeInterval'] = '6-12'\n",
    "train.loc[(train['Age'] > 12) & (train['Age'] <= 24),'AgeInterval'] = '12-24'\n",
    "train.loc[(train['Age'] > 24) & (train['Age'] <= 48),'AgeInterval'] = '24-48'\n",
    "train.loc[(train['Age'] > 48) & (train['Age'] <= 120),'AgeInterval'] = '48-120'\n",
    "train.loc[train['Age'] > 120,'AgeInterval'] = '>120'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7dd19a0f954003eeefa947e713a99f69273f2fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(x=\"AdoptionSpeed\", hue=\"AgeInterval\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "635ff688bc2a556ad8764c194ecd46072863a3b3"
   },
   "outputs": [],
   "source": [
    "total = train[train.AgeInterval == '0-3'].size\n",
    "interval1 = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.AgeInterval == '0-3')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.AgeInterval == '0-3')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.AgeInterval == '0-3')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.AgeInterval == '0-3')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.AgeInterval == '0-3')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(interval1, [])\n",
    "types = (['0-3'] * 5)\n",
    "\n",
    "feePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 1, hue='type', style='type', markers=True, data=feePercentDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6adbab191ea22f92914f395dc654b4eb6cbd4b55"
   },
   "source": [
    "Findings:\n",
    "* We have a lot of puppies in our dataset\n",
    "* The mean age tends to grow on pets that are more time for adoption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4bee548802ec9e1e5cecaffe5c16061e532f819"
   },
   "source": [
    "#### **Quantity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33d138b4790e1bc369d32ccc4b68cb0031e8b63f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.distplot(train.Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b38d86abc0f39081d77fdf178c1241921c1150f5"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"Quantity\", y=\"AdoptionSpeed\", data=train, kind=\"reg\", height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a20d7718dca53841bb8321e255a2c23310d4d62e"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"AdoptionSpeed\", y=\"Quantity\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9be973781c3ca51c4db33df2127fe453cd00fe40"
   },
   "source": [
    "Findings:\n",
    "* Normally we have 1 pet per adoption\n",
    "* We can see that the mean of quantity for adoption increases for later adoptions and non adopted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51fdb58d82fffa770bd5773bd536256eec725b63"
   },
   "source": [
    "#### **VideoAmt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9210cb174589bb7ce4aee872e695cf370658a19a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.distplot(train.VideoAmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "603f0cf9f3ba6ba2286011de65671891d57a2e84"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"VideoAmt\", y=\"AdoptionSpeed\", data=train, kind=\"reg\", height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d24d1e9d8823f90f3b3be5257fccce1042c8effd"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"AdoptionSpeed\", y=\"VideoAmt\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69c1b87ace7ac7e3b6778aaca9f6285b3e414675"
   },
   "source": [
    "Findings: The amount of videos doesn't seem to have much impact in AdoptionSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84a265648ade7b3ddb15ce1c4863116d3214ee94"
   },
   "source": [
    "#### **PhotoAmt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b0b085d34b6df012a254143465f935819595f5e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.distplot(train.PhotoAmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d832327e6f82c51dc7749aec92428597e25810d5"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"PhotoAmt\", y=\"AdoptionSpeed\", data=train, kind=\"reg\", height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f6e667817f25ff4552bbdd0032f0d77792a9095"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"AdoptionSpeed\", y=\"PhotoAmt\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f25ef35b7e71fe98316508d16bfffa4ef3826d80"
   },
   "outputs": [],
   "source": [
    "train['PhotoAmtInterval'] = pd.Series(['0', '1', '2', '3', '4', '5', '>5'], dtype='category')\n",
    "train.loc[train['PhotoAmt'] == 0 ,'PhotoAmtInterval'] = '0'\n",
    "train.loc[train['PhotoAmt'] == 1 ,'PhotoAmtInterval'] = '1'\n",
    "train.loc[train['PhotoAmt'] == 2 ,'PhotoAmtInterval'] = '2'\n",
    "train.loc[train['PhotoAmt'] == 3 ,'PhotoAmtInterval'] = '3'\n",
    "train.loc[train['PhotoAmt'] == 4 ,'PhotoAmtInterval'] = '4'\n",
    "train.loc[train['PhotoAmt'] == 5 ,'PhotoAmtInterval'] = '5'\n",
    "train.loc[train['PhotoAmt'] > 5 ,'PhotoAmtInterval'] = '>5'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(x='AdoptionSpeed', hue='PhotoAmtInterval', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48407f3e7e00889462a51bfc6bde99fcc88c6d41"
   },
   "source": [
    "Findings:\n",
    "* The majority of pets that have no pictures are on AdoptionSpeed 4\n",
    "* It seems that putting 1-3 pictures it's relevant for getting adopted, more than that not so much.\n",
    "* I assume from the >5 trend that people tend to add more picture when non-adopted time increases but after a certain threshold that trend stops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1e4904994dc61a97ba4910a116de5d8415b3329"
   },
   "source": [
    "#### **Fee**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40491135eaa10e76fd5563aa83f5ba0164363c54"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.distplot(train.Fee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2394ea34391053a6431adea4df3fdde1ce79dfe8"
   },
   "source": [
    "**We clearly have some outliers here on Fee, let's remove them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e14a8915a2a75846a6d8461babe3ff5b30a5304a"
   },
   "outputs": [],
   "source": [
    "train = train[train.Fee <= 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47ff265eea61219c6fc1fab853193f655c39e15c"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Fee', y='AdoptionSpeed', data=train, kind='reg', height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e4d5573d3555404b2e1bf068f883a8dd0d9d6d9"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='AdoptionSpeed', y='Fee', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8784333ae240ff8b6d2e33ab85ca0d155e1bdb4"
   },
   "outputs": [],
   "source": [
    "train['FeeInterval'] = pd.Series(['Free', 'Paid'], dtype='category')\n",
    "train.loc[train['Fee'] == 0 ,'FeeInterval'] = 'Free'\n",
    "train.loc[train['Fee'] > 0 ,'FeeInterval'] = 'Paid'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(x='AdoptionSpeed', hue='FeeInterval', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1604a14eea80a9c0e5a464fdd138c7ed6a683311"
   },
   "outputs": [],
   "source": [
    "total = train[train.Fee == 0].size\n",
    "feeFreePercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Fee == 0)].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Fee == 0)].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Fee == 0)].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Fee == 0)].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Fee == 0)].size\n",
    "] / total\n",
    "\n",
    "total = train[train.Fee > 0].size\n",
    "feePaidPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Fee > 0)].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Fee > 0)].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Fee > 0)].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Fee > 0)].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Fee > 0)].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(feeFreePercent, feePaidPercent)\n",
    "types = (['free'] * 5) + (['paid'] * 5)\n",
    "\n",
    "feePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 2, hue='type', style='type', markers=True, data=feePercentDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c47ee67ad73407a605537b9631e078650ce6931f"
   },
   "source": [
    "Findings: \n",
    "* Proportionally we have more `paid` pets on non adopt class.\n",
    "* We can conclude that charging for a fee can increases your changes of not being adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93b7b5781b8c83a6e44758174121ec7650ba138f"
   },
   "source": [
    "## **Categorical attributes and outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e52ceed598227e68b9d6bde7898d0810174b03e"
   },
   "source": [
    "#### **Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f235078c09fd7e192a3b96b6496ed37537dff32d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 = Dog, 2 = Cat\n",
    "sns.catplot(x=\"Type\", kind=\"count\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b02307166d5fdad04a9db036901ee5ddc2765a8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Type', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df0b3dceffb163afd6182bc53fc196c607335e51"
   },
   "outputs": [],
   "source": [
    "total = train[train.Type == 'Dog'].size\n",
    "dogPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Dog')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Dog')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Dog')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Dog')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Dog')].size\n",
    "] / total\n",
    "\n",
    "total = train[train.Type == 'Cat'].size\n",
    "catPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Cat')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Cat')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Cat')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Cat')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Cat')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(dogPercent, catPercent)\n",
    "types = (['dog'] * 5) + (['cat'] * 5)\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 2, hue='type', style='type', markers=True, data=typePercentDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a29468e14789bfe92a6e69797f742a104372221"
   },
   "source": [
    "Findings:\n",
    "* Cats seems to have a higher adoption speed than dogs.\n",
    "* Both follow the same trend. Up trend on first month and then the probability of being adopted drops.\n",
    "* The probability of non adoption seems to be higher for dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cc14202d8e966334e327b9ae09fa1cd8f21f1c6"
   },
   "source": [
    "#### **Breed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9dffd6a1ea02985cf5043a1c847339ba418e08fd"
   },
   "outputs": [],
   "source": [
    "dogCounts = train[train.Type == 'Dog'].Breed1.value_counts()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "dogCounts.nlargest(15).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e7f4dac1a770ff6c852d6444250dc544b8c3c13"
   },
   "outputs": [],
   "source": [
    "catCounts = train[train.Type == 'Cat'].Breed1.value_counts()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "catCounts.nlargest(15).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41445d0088a1bee30c586f097ebce89a87a733bf"
   },
   "outputs": [],
   "source": [
    "strayCat = ['Domestic Short Hair', 'Domestic Medium Hair', 'Domestic Long Hair']\n",
    "strayDog = ['Mixed Breed']\n",
    "\n",
    "train.loc[(train.Breed1.isin(strayDog)) & (train.Type == 'Dog'), 'Breed1Type'] = 'Stray'\n",
    "train.loc[(train.Breed1.isin(strayCat)) & (train.Type == 'Cat'), 'Breed1Type'] = 'Stray'\n",
    "train.loc[(~train.Breed1.isin(strayDog)) & (train.Type == 'Dog'), 'Breed1Type'] = 'Breed'\n",
    "train.loc[(~train.Breed1.isin(strayCat)) & (train.Type == 'Cat'), 'Breed1Type'] = 'Breed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61e462f91ca00d8c4b509e50cb5564f2203b5431"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='AdoptionSpeed', hue='Breed1Type', data=train[train.Type == 'Dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a8afed3ab0a3a16a44aebfe07906bfec60df080"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='AdoptionSpeed', hue='Breed1Type', data=train[train.Type == 'Cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f320db87db9b50a1aab694137d53b89e110d4f25"
   },
   "outputs": [],
   "source": [
    "total = train[(train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size\n",
    "dogPercentStray = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Dog') & (train.Breed1Type == 'Stray')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size\n",
    "dogPercentBreed = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Dog') & (train.Breed1Type == 'Breed')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size\n",
    "catPercentStray = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Cat') & (train.Breed1Type == 'Stray')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size\n",
    "catPercentBreed = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Type == 'Cat') & (train.Breed1Type == 'Breed')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(dogPercentStray, dogPercentBreed)\n",
    "percents = np.append(percents, catPercentStray)\n",
    "percents = np.append(percents, catPercentBreed)\n",
    "types = (['dog-stray'] * 5 + ['dog-breed'] * 5 + ['cat-stray'] * 5 + ['cat-breed'] * 5)\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 4, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6217cb9942144ecfec19a9457ccc3d48d087a82b"
   },
   "source": [
    "Findings:\n",
    "* We have more stray dogs than cats proporcionally\n",
    "* Stray dogs have a greater likelihood to not be adopted\n",
    "* Stray cats are adopted at the same rate as with breed. People don't care much about breeds of cats appearently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f3c44269abcf707f5b43240943fbcf3cb783067"
   },
   "source": [
    "#### **Color**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eeb83508f09ec9f073774b5a8aa6b6efea869fa6"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Color1', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a6900057a42b4bf49b2b5aea540d6e337e6ac0f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Color1', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cebc83e9772fda720e87c858f26c510cc4392280"
   },
   "source": [
    "Findings: clearly color doesn't have much effect on AdoptionSpeed. It follows always the same proportional in all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e25707060e7504292012a173063414b793e70b4"
   },
   "source": [
    "#### **MaturitySize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e64bff17dc1ecdf00c92764e71d998438ba20ded"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='MaturitySize', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fcc06ae2ce095e25571a4c7b15ee284203f333c"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='MaturitySize', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e96326f676e9fbb3f5a9ba1a6782340f2ddcae5"
   },
   "outputs": [],
   "source": [
    "total = train[(train.MaturitySize == 'Large')].size\n",
    "largePercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.MaturitySize == 'Large')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.MaturitySize == 'Large')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.MaturitySize == 'Large')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.MaturitySize == 'Large')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.MaturitySize == 'Large')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.MaturitySize == 'Medium')].size\n",
    "mediumPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.MaturitySize == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.MaturitySize == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.MaturitySize == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.MaturitySize == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.MaturitySize == 'Medium')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.MaturitySize == 'Small')].size\n",
    "smallPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.MaturitySize == 'Small')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.MaturitySize == 'Small')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.MaturitySize == 'Small')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.MaturitySize == 'Small')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.MaturitySize == 'Small')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(largePercent, mediumPercent)\n",
    "percents = np.append(percents, smallPercent)\n",
    "types = (['Large'] * 5 + ['Medium'] * 5 + ['Small'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24c17da3b1a4331ecf6e1ef8f2db0ad1f19af3d5"
   },
   "source": [
    "Findings:\n",
    "* We have a lot of Medium pets\n",
    "* Large and Small are more likely to be adopted in the first week than Medium\n",
    "* All follow the same trends\n",
    "* Small has a greater change to be adopted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d7ee340f7d14228d23f5ec08b051cefb5a20ddc"
   },
   "source": [
    "#### **FurLength**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9afdbe55c1bcbc6936ef3ff3c435b59086a456aa"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='FurLength', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e590bec90341e16b0f90cf2a00e9dd3b14678091"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='FurLength', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0e4a9fb3d71d5c599585cb00704bdd7953a0bee"
   },
   "outputs": [],
   "source": [
    "total = train[(train.FurLength == 'Long')].size\n",
    "longPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.FurLength == 'Long')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.FurLength == 'Long')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.FurLength == 'Long')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.FurLength == 'Long')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.FurLength == 'Long')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.FurLength == 'Medium')].size\n",
    "mediumPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.FurLength == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.FurLength == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.FurLength == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.FurLength == 'Medium')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.FurLength == 'Medium')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.FurLength == 'Short')].size\n",
    "shortPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.FurLength == 'Short')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.FurLength == 'Short')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.FurLength == 'Short')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.FurLength == 'Short')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.FurLength == 'Short')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(longPercent, mediumPercent)\n",
    "percents = np.append(percents, shortPercent)\n",
    "types = (['Long'] * 5 + ['Medium'] * 5 + ['Short'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ead2290444b662672d2bc59886ad54b22b49af9"
   },
   "source": [
    "Findings:\n",
    "* Long fur have a high adoption rate in the first week and the lowest probability of not being adopted after 100 days\n",
    "* Short fur have the highest probability of not being adopted after 100 days\n",
    "* My conclusion is that pets with long furs tend to appear more cute and that has a huge impact in a decision to adopt or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "524f2640b07f03d3e067ebb62f7454cf8f2b7e9b"
   },
   "source": [
    "#### **Vaccinated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbdd71c0d9cbd739b87655d8f3b2fbe24ee65c5c"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Vaccinated', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e9dd7d4a0de8547e6e4ed6e5bfa125425d8f2eb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Vaccinated', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3f7670edd42c8aa06913ca6f0ce490d82c40091"
   },
   "outputs": [],
   "source": [
    "total = train[(train.Vaccinated == 'Yes')].size\n",
    "yesPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Vaccinated == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Vaccinated == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Vaccinated == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Vaccinated == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Vaccinated == 'Yes')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Vaccinated == 'No')].size\n",
    "noPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Vaccinated == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Vaccinated == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Vaccinated == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Vaccinated == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Vaccinated == 'No')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Vaccinated == 'Not Sure')].size\n",
    "notSurePercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Vaccinated == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Vaccinated == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Vaccinated == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Vaccinated == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Vaccinated == 'Not Sure')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(yesPercent, noPercent)\n",
    "percents = np.append(percents, notSurePercent)\n",
    "types = (['Yes'] * 5 + ['No'] * 5 + ['Not Sure'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83b63795e0af9930946b921cab05acf063becd5c"
   },
   "source": [
    "Findings: Being Vaccinated doesn't seem to be relevant to be adopted or not. Appearently if the adopter likes the pet for other features that end up being irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "648f1934de598eabc51901278a6808f9737206e3"
   },
   "source": [
    "#### **Dewormed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce02d09a8e6b2f65912b78be81ff67e157eed503"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Dewormed', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c6d7d77360bcd06d85964ae7494660209a28689"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Dewormed', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12ad78ae06e5bb1efa5d626e5afd30ed545efe2d"
   },
   "outputs": [],
   "source": [
    "total = train[(train.Dewormed == 'Yes')].size\n",
    "yesPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Dewormed == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Dewormed == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Dewormed == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Dewormed == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Dewormed == 'Yes')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Dewormed == 'No')].size\n",
    "noPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Dewormed == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Dewormed == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Dewormed == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Dewormed == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Dewormed == 'No')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Dewormed == 'Not Sure')].size\n",
    "notSurePercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Dewormed == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Dewormed == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Dewormed == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Dewormed == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Dewormed == 'Not Sure')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(yesPercent, noPercent)\n",
    "percents = np.append(percents, notSurePercent)\n",
    "types = (['Yes'] * 5 + ['No'] * 5 + ['Not Sure'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc97c47db8a26782ad789e783ab5b3889105a3ef"
   },
   "source": [
    "Findings: Dewormed seems to have the same impact as Vaccinated. I assume that other features define the decision of the adopter and vaccinate and deworm it's just something it's not really a deal breaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d151a5827cfb7dd7fed38ae442177ff1b309439"
   },
   "source": [
    "#### **Sterilized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb36e6a784d6b69ccb6fdd74ef8120e55ffabeb3"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Sterilized', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8574bf5e2eb6c4abf0cc3681f71a39bb121e4242"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Sterilized', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed4c0ae942c7c433d9ae4468b780179851c59062"
   },
   "outputs": [],
   "source": [
    "total = train[(train.Sterilized == 'Yes')].size\n",
    "yesPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Sterilized == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Sterilized == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Sterilized == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Sterilized == 'Yes')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Sterilized == 'Yes')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Sterilized == 'No')].size\n",
    "noPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Sterilized == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Sterilized == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Sterilized == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Sterilized == 'No')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Sterilized == 'No')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Sterilized == 'Not Sure')].size\n",
    "notSurePercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Sterilized == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Sterilized == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Sterilized == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Sterilized == 'Not Sure')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Sterilized == 'Not Sure')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(yesPercent, noPercent)\n",
    "percents = np.append(percents, notSurePercent)\n",
    "types = (['Yes'] * 5 + ['No'] * 5 + ['Not Sure'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e9ad0e845af8473139d6e29cf7523fe9b09aa28"
   },
   "source": [
    "Findings: Being Sterilizzed doesn't seem to have impact in being adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20686fa0f7e047e5937cb028a602f833a4aff14f"
   },
   "source": [
    "#### **Health**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ff67a48d371011df98eb6a46cda400eac207a34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Health', kind='count', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82210374ecadffac1ff3ee77de1d009ad3479d30"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(x='AdoptionSpeed', hue='Health', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1981585edcdbc8cac46b68412e08ab87e235372"
   },
   "outputs": [],
   "source": [
    "total = train[(train.Health == 'Healthy')].size\n",
    "healthyPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Health == 'Healthy')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Health == 'Healthy')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Health == 'Healthy')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Health == 'Healthy')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Health == 'Healthy')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Health == 'Minor Injury')].size\n",
    "minorPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Health == 'Minor Injury')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Health == 'Minor Injury')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Health == 'Minor Injury')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Health == 'Minor Injury')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Health == 'Minor Injury')].size\n",
    "] / total\n",
    "\n",
    "total = train[(train.Health == 'Serious Injury')].size\n",
    "seriousPercent = [\n",
    " train[(train.AdoptionSpeed == 0) & (train.Health == 'Serious Injury')].size,\n",
    " train[(train.AdoptionSpeed == 1) & (train.Health == 'Serious Injury')].size,\n",
    " train[(train.AdoptionSpeed == 2) & (train.Health == 'Serious Injury')].size,\n",
    " train[(train.AdoptionSpeed == 3) & (train.Health == 'Serious Injury')].size,\n",
    " train[(train.AdoptionSpeed == 4) & (train.Health == 'Serious Injury')].size\n",
    "] / total\n",
    "\n",
    "percents = np.append(healthyPercent, minorPercent)\n",
    "percents = np.append(percents, seriousPercent)\n",
    "types = (['Healthy'] * 5 + ['Minor Injury'] * 5 + ['Serious Injury'] * 5 )\n",
    "\n",
    "typePercentDf = pd.DataFrame({ 'percent': percents, 'type': types })\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(y='percent', x=[0, 1, 2, 3, 4] * 3, hue='type', style='type', markers=True, data=typePercentDf, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "928f4da845a1649dd8bc8b5889742b0c8c24c03e"
   },
   "source": [
    "Findings:\n",
    "* Being healthy has a lower probability of not being adopted after 100 days\n",
    "* The more serious the injuries higher are the chances of not being adopted after 100 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb9947bfe1269484a539b45ff0f121ec18706713"
   },
   "source": [
    "## **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f392391d93c3a24dd83a2ce27df62aae111cb708"
   },
   "source": [
    "### **Catboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fe2023518695b8ab40b2b89ec73326aba4d5e42"
   },
   "outputs": [],
   "source": [
    "target = 'AdoptionSpeed'\n",
    "# categoricalFeatures = list(set(categoricalFeatures) - set([target, 'State', 'RescuerID', 'PetID', 'Color2', 'Color3', 'Breed2']))\n",
    "#numericalFeatures = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt']\n",
    "# catFeaturesIndex = list(range(0, len(categoricalFeatures)))\n",
    "\n",
    "# cateogrical features to train\n",
    "categorical = ['Type', 'Breed1', 'Gender', 'Color1', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State']\n",
    "\n",
    "features = categorical + numericalFeatures\n",
    "data = train[features + [target]].dropna()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "875adc2b3fdaa5cba5d95bc45c23cd881bd69647",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data = FeaturesData(\n",
    "#     num_feature_data=X_train[numericalFeatures].astype('float32').values,\n",
    "#     cat_feature_data=X_train[categoricalFeatures].__array__(dtype=object)\n",
    "# )\n",
    "\n",
    "# train_labels = y_train.astype('int').values\n",
    "\n",
    "# clf = CatBoostClassifier(loss_function='MultiClass', verbose=True, depth=10, iterations= 100, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "# clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82687e275445ec5b2a39f19bca08ee778dd5dc48"
   },
   "source": [
    "**Confusion Matrix to compare predictions per class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25a5b58415c540edccf3dae1723a6696e94a2f22"
   },
   "outputs": [],
   "source": [
    "# test_data = FeaturesData(\n",
    "#     num_feature_data=X_test[numericalFeatures].astype('float32').values,\n",
    "#     cat_feature_data=X_test[categoricalFeatures].__array__(dtype=object)\n",
    "# )\n",
    "\n",
    "# test_labels = y_test.astype('int').values\n",
    "# y_predicted = clf.predict(test_data)\n",
    "\n",
    "def generateConfusionMatrix(y_real, y_predicted):\n",
    "    cm = pd.DataFrame()\n",
    "    cm['Satisfaction'] = y_real\n",
    "    cm['Predict'] = y_predicted\n",
    "    mappingSatisfaction = {0:'Same Day', 1: 'First Week', 2: 'First Month', 3: '2-3 Month', 4: 'Non-Adopted >100'}\n",
    "    mappingPredict = {0.0:'Same Day', 1.0: 'First Week', 2.0: 'First Month', 3.0: '2-3 Month', 4.0: 'Non-Adopted >100'}\n",
    "    cm = cm.replace({'Satisfaction': mappingSatisfaction, 'Predict': mappingPredict})\n",
    "    return pd.crosstab(cm['Satisfaction'], cm['Predict'], margins=True)\n",
    "\n",
    "# generateConfusionMatrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f471154ed9b280b2de295bb20b3e61459a4581ce"
   },
   "source": [
    "**Model score on test data split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d2e99aabe87d3e1e746904c571f594f3ff448c0"
   },
   "outputs": [],
   "source": [
    "# clf.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0228957a570fa2f5adea68cf1f3b9cca79d0c078"
   },
   "source": [
    "**Check most relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0195add98f54ff39c5ff2a2b697a0663d18494f"
   },
   "outputs": [],
   "source": [
    "def plotMostRelevantFeatures(indexes, model, train_data, train_labels, title='Feature Importance Ranking'):\n",
    "    feature_score = pd.DataFrame(list(zip(indexes, model.get_feature_importance(Pool(train_data, label=train_labels)))),\n",
    "                columns=['Feature','Score'])\n",
    "    feature_score = feature_score.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "    ax = feature_score.plot('Feature', 'Score', kind='bar', color='c')\n",
    "    ax.set_title(title, fontsize = 14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    rects = ax.patches\n",
    "\n",
    "    # get feature score as labels round to 2 decimal\n",
    "    labels = feature_score['Score'].round(2)\n",
    "\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 0.35, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plotMostRelevantFeatures(X_train.dtypes.index, clf, train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "42b15830683ebe1b796225b93ccd77914ba6f3ed"
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3310aa16f1490bea0f8be25339d66d357cca553c"
   },
   "outputs": [],
   "source": [
    "# bestCatFeatures = ['Sterilized', 'Breed1', 'Type', 'MaturitySize', 'FurLength', 'Gender', 'Health', 'Color1', 'Fee', 'Vaccinated']\n",
    "# bestNumFeatures = ['Age', 'Quantity', 'PhotoAmt']\n",
    "\n",
    "# train_data = FeaturesData(\n",
    "#     num_feature_data=X_train[bestNumFeatures].astype('float32').values,\n",
    "#     cat_feature_data=X_train[bestCatFeatures].__array__(dtype=object)\n",
    "# )\n",
    "\n",
    "# train_labels = y_train.astype('int').values\n",
    "\n",
    "# clf = CatBoostClassifier(loss_function='MultiClass', verbose=False, depth=10, iterations= 100, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "# clf.fit(data[mostImportantFeatures], data[target], cat_features= mostImportantCatIndex, plot=False)\n",
    "# predictions = clf.predict(test[mostImportantFeatures])\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30f300bcd212fc29f2c6d657216da12604afb7de"
   },
   "outputs": [],
   "source": [
    "# test['AdoptionSpeed'] = predictions\n",
    "# test.AdoptionSpeed = test['AdoptionSpeed'].map({0.0: '0', 1.0: '1', 2.0: '2', 3.0: '3', 4.0: '4'})\n",
    "# test[['PetID', 'AdoptionSpeed']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d2b2ba19be96b4337b6e894a407b68b3d3c98ce"
   },
   "outputs": [],
   "source": [
    "def calculateClassificationScores(y_true, y_predicted, model, X_test, average='macro'):\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "    f1 = f1_score(y_true, y_predicted, average=average)\n",
    "    precision = precision_score(y_true, y_predicted, average=average)\n",
    "    recall = recall_score(y_true, y_predicted, average=average)\n",
    "    if model and isinstance(model, CatBoostClassifier):\n",
    "        score = model.get_best_score()\n",
    "        if score.get('validation_0'):\n",
    "            multiclass = score['validation_0']['MultiClass']\n",
    "        else:\n",
    "            multiclass = model.score(X_test, y_true)\n",
    "        return (accuracy, f1, precision, recall, multiclass)\n",
    "    \n",
    "    return (accuracy, f1, precision, recall)\n",
    "\n",
    "def crossValidation(params, X, y):\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    multiclass_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X.values, y.values):\n",
    "        \n",
    "        X_train = X[X.index.isin(train_index)]\n",
    "        X_train = FeaturesData(\n",
    "            num_feature_data=X_train[numericalFeatures].astype('float32').values,\n",
    "            cat_feature_data=X_train[categoricalFeatures].__array__(dtype=object)\n",
    "        )\n",
    "        y_train = y[y.index.isin(train_index)].astype('int').values\n",
    "        \n",
    "        X_valid = X[X.index.isin(val_index)]\n",
    "        X_valid = FeaturesData(\n",
    "            num_feature_data=X_valid[numericalFeatures].astype('float32').values,\n",
    "            cat_feature_data=X_valid[categoricalFeatures].__array__(dtype=object)\n",
    "        )\n",
    "        y_valid = y[y.index.isin(val_index)].astype('int').values\n",
    "        \n",
    "        pool_test = Pool(X_valid, label=y_valid)\n",
    "        \n",
    "        clf = CatBoostClassifier(\n",
    "            loss_function='MultiClass',\n",
    "            verbose=False,\n",
    "            depth=params['depth'],\n",
    "            iterations=params['iterations'],\n",
    "            l2_leaf_reg=params['l2_leaf_reg'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            task_type='CPU'\n",
    "        )\n",
    "        \n",
    "        clf.fit(X_train, y_train, eval_set=pool_test, use_best_model=True)\n",
    "        \n",
    "        y_pred = clf.predict(X_valid)\n",
    "        \n",
    "        # calculateClassificationScores(y_test, y_predicted, clfSentiment, X_test_pool)\n",
    "        \n",
    "        (accuracy, f1, precision, recall, multiclass) = calculateClassificationScores(y_valid, y_pred, clf, X_valid)\n",
    "        \n",
    "        multiclass_scores.append(multiclass)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "    return (multiclass_scores, accuracy_scores, f1_scores, precision_scores, recall_scores)\n",
    "    \n",
    "\n",
    "def searchBestParams(grid, X, y):\n",
    "    catboostDf = pd.DataFrame({\n",
    "        'model':[],\n",
    "        'multiclass_score_mean':[],\n",
    "        'multiclass_score_std':[],\n",
    "        'f1_score_mean':[],\n",
    "        'f1_score_std':[],\n",
    "        'accuracy_score_mean':[],\n",
    "        'accuracy_score_std':[],\n",
    "        'precision_score_mean':[],\n",
    "        'precision_score_std':[],\n",
    "        'recall_score_mean':[],\n",
    "        'recall_score_std':[],\n",
    "        'params': []}\n",
    "    )\n",
    "    for params in grid:\n",
    "        print(params)\n",
    "        (multiclass_scores, accuracy_scores, f1_scores, precision_scores, recall_scores) = crossValidation(params, X, y)\n",
    "        catboostDf = catboostDf.append({\n",
    "            'multiclass_score_mean': np.mean(multiclass_scores),\n",
    "            'multiclass_score_std': np.std(multiclass_scores),\n",
    "            'f1_score_mean': np.mean(f1_scores),\n",
    "            'f1_score_std': np.std(f1_scores),\n",
    "            'accuracy_score_mean': np.mean(accuracy_scores),\n",
    "            'accuracy_score_std': np.std(accuracy_scores),\n",
    "            'precision_score_mean': np.mean(precision_scores),\n",
    "            'precision_score_std': np.std(precision_scores),\n",
    "            'recall_score_mean': np.mean(recall_scores),\n",
    "            'recall_score_std': np.std(recall_scores),\n",
    "            'params': params\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return catboostDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9bf1f708cd6d242065be6edbc9cc3fe9494f94e3"
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'depth':[6, 8, 10, 14, 20],\n",
    "#     'iterations':[100, 150, 200, 300, 500, 1000],\n",
    "#     'learning_rate':[0.15], \n",
    "#     'l2_leaf_reg':[12]\n",
    "# }\n",
    "\n",
    "# print(numericalFeatures + categoricalFeatures)\n",
    "\n",
    "# grid = ParameterGrid(params)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# bestScores = []\n",
    "# X = data[numericalFeatures + categoricalFeatures]\n",
    "# y = data[target]\n",
    "\n",
    "# catboostDf = searchBestParams(grid, X, y)\n",
    "\n",
    "# run only if you want to check a new combination of params\n",
    "# catboostDf = searchBestParams(grid, X, y)\n",
    "# bestCatModel = catboostDf[catboostDf.f1_score_mean == catboostDf.f1_score_mean.max()]\n",
    "# bestCatModel.params.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d72b9912c1f09528f4e9363d4e79d622e19a1b1d"
   },
   "outputs": [],
   "source": [
    "# catboostDf.sort_values(by=['f1_score_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a1340b1a1a460fd0fe38a9cca75e2880df3d52b"
   },
   "source": [
    "Best params: {'depth': 8,\n",
    " 'iterations': 140,\n",
    " 'l2_leaf_reg': 12,\n",
    " 'learning_rate': 0.15,\n",
    " 'thread_count': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4375321cff10b4fe0b52394461e19da257d998ea"
   },
   "source": [
    "Evaluate model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5a76d998b52c143ef9c908c5d1b99dee92df08f"
   },
   "outputs": [],
   "source": [
    "# categoricalFeatures = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n",
    "#                        'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "#                        'Health', 'State', 'RescuerID', 'AdoptionSpeed']\n",
    "\n",
    "# target = 'AdoptionSpeed'\n",
    "# categoricalFeatures = ['Type', 'Breed1', 'Gender', 'Color1', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "#                        'Health']\n",
    "# numericalFeatures = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9decf15b97db4ac16967fbe49d065cbb75b3a75"
   },
   "outputs": [],
   "source": [
    "def trainCatboost(numericalFeatures, categoricalFeatures, target, data, params=None):\n",
    "    print(numericalFeatures)\n",
    "    print(categoricalFeatures)\n",
    "    print(target)\n",
    "    print(data.size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[numericalFeatures + categoricalFeatures],\n",
    "        data[target],\n",
    "        test_size=0.25,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train_pool = FeaturesData(\n",
    "        num_feature_data=X_train[numericalFeatures].astype('float32').values,\n",
    "        cat_feature_data=X_train[categoricalFeatures].__array__(dtype=object)\n",
    "    )\n",
    "    y_train_pool = y_train.astype('int').values\n",
    "\n",
    "    X_test_pool = FeaturesData(\n",
    "        num_feature_data=X_test[numericalFeatures].astype('float32').values,\n",
    "        cat_feature_data=X_test[categoricalFeatures].__array__(dtype=object)\n",
    "    )\n",
    "    y_test_pool = y_test.astype('int').values\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    if params:\n",
    "        model = CatBoostClassifier(\n",
    "            loss_function='MultiClass',\n",
    "            verbose=False,\n",
    "            depth=params['depth'],\n",
    "            iterations=params['iterations'],\n",
    "            l2_leaf_reg=params['l2_leaf_reg'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            task_type='GPU',\n",
    "            class_weights=[4, 1, 1, 1, 1]\n",
    "        )\n",
    "    else:\n",
    "        model = CatBoostClassifier(\n",
    "            loss_function='MultiClass',\n",
    "            verbose=False,\n",
    "            depth=8,\n",
    "            iterations=140,\n",
    "            l2_leaf_reg=12,\n",
    "            learning_rate=0.15,\n",
    "            task_type='GPU',\n",
    "            class_weights=[4, 1, 1, 1, 1]\n",
    "        )\n",
    "\n",
    "    model.fit(X_train_pool, y_train_pool,logging_level='Silent')\n",
    "    \n",
    "    y_predicted = model.predict(X_test_pool)\n",
    "    return (model, y_predicted, X_train, y_train, X_train_pool, X_test_pool, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb434d311af70833914e9c9bbae09fff3746f015"
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'depth':8,\n",
    "#     'iterations': 140,\n",
    "#     'learning_rate': 0.15, \n",
    "#     'l2_leaf_reg': 12\n",
    "# }\n",
    "\n",
    "# (bestClf, \n",
    "#  y_predicted, \n",
    "#  X_train, \n",
    "#  y_train, \n",
    "#  X_train_pool,\n",
    "#  X_test_pool,\n",
    "#  y_test) = trainCatboost(numericalFeatures, categorical, target, data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95228afaab786fbbeebcd2974653707b4136254d"
   },
   "outputs": [],
   "source": [
    "# scores = calculateClassificationScores(y_test, y_predicted, bestClf, X_test_pool)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f multiclass: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4afc4382d9c98b548bebb4325531befd0f7e573d"
   },
   "outputs": [],
   "source": [
    "# generateConfusionMatrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fea63afae11fea5cb8de82210dce214a8012bdc"
   },
   "outputs": [],
   "source": [
    "# np.sum(y_predicted == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf7a4c8b2a5a2660117d5fe8e69f56d92b451c1e"
   },
   "outputs": [],
   "source": [
    "# plotMostRelevantFeatures(X_train.dtypes.index, bestClf, X_train_pool, y_train.astype('int').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d07477d83ba9a50d16bbc2ce07bfda0068f954cc"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ee4e387fb8a5bdb37571ee2ac7afaca302c6096"
   },
   "source": [
    "Sentiment Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9cfb9a6cc8493d39ba98f1df0818141c1286b085"
   },
   "outputs": [],
   "source": [
    "# targetSentiment = 'AdoptionSpeed'\n",
    "# categoricalFeaturesSentiment = ['Type', 'Breed1', 'Gender', 'Color1', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "#                        'Health']\n",
    "# numericalFeaturesSentiment = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt', 'sentiment_document_score', 'sentiment_document_magnitude']\n",
    "\n",
    "# trying new set of features from different models\n",
    "# categoricalFeaturesSentiment = ['Breed1', 'Sterilized', 'Vaccinated', 'MaturitySize', 'Gender']\n",
    "# numericalFeaturesSentiment = ['sentiment_document_magnitude', 'Age', 'PhotoAmt', 'Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bd0802d56ac346b2ecf02c69ca1b838b71291dc"
   },
   "outputs": [],
   "source": [
    "# msno.matrix(train[categoricalFeaturesSentiment + numericalFeaturesSentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e7b2888e02eaa6ef511d32e12b2af5a1ee7846c"
   },
   "outputs": [],
   "source": [
    "# params = {'depth': 6, 'iterations': 300, 'l2_leaf_reg': 12, 'learning_rate': 0.15}\n",
    "\n",
    "# (clfSentiment, \n",
    "#  y_predicted, \n",
    "#  X_train, \n",
    "#  y_train, \n",
    "#  X_train_pool,\n",
    "#  X_test_pool,\n",
    "#  y_test) = trainCatboost(numericalFeaturesSentiment, categoricalFeaturesSentiment, targetSentiment, train[categoricalFeaturesSentiment + numericalFeaturesSentiment + [targetSentiment]].dropna(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07a72a170f04c592f4c9bfe560c2fcf42c5dbf89"
   },
   "outputs": [],
   "source": [
    "# scores = calculateClassificationScores(y_test, y_predicted, clfSentiment, X_test_pool)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f multiclass: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3ca3bde9bfef260c6a8d65612541fd60858bef1"
   },
   "outputs": [],
   "source": [
    "# generateConfusionMatrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30a36fe070dd9df638d29c5a460cd2aae6c2edc8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotMostRelevantFeatures(X_train.dtypes.index, bestClf, X_train_pool, y_train.astype('int').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e792dcc3fdd40f70125331206d895414cda026ca"
   },
   "outputs": [],
   "source": [
    "# search best params for new features\n",
    "# params = {\n",
    "#     'depth':[6, 8, 10, 12],\n",
    "#     'iterations':[100, 150, 300],\n",
    "#     'learning_rate':[0.15], \n",
    "#     'l2_leaf_reg':[12]\n",
    "# }\n",
    "\n",
    "# grid = ParameterGrid(params)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "#dataS = train[numericalFeaturesSentiment + categoricalFeaturesSentiment + [targetSentiment]].dropna()\n",
    "\n",
    "#bestScores = []\n",
    "#X = dataS[numericalFeaturesSentiment + categoricalFeaturesSentiment]\n",
    "#y = dataS[targetSentiment]\n",
    "\n",
    "#catboostDf = searchBestParams(grid, X, y)\n",
    "#bestCatModel = catboostDf[catboostDf.f1_score_mean == catboostDf.f1_score_mean.max()]\n",
    "#bestCatModel.params.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c54934f767b564e51cda449c381981643ba55bca"
   },
   "source": [
    "{'depth': 6, 'iterations': 300, 'l2_leaf_reg': 12, 'learning_rate': 0.15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54e47112eceedcc32a0d01a675311f6cc14fe13b"
   },
   "outputs": [],
   "source": [
    "#bestCatModel.f1_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b9ab1cd504b8d903e226ef012e884a3d9eb8293"
   },
   "outputs": [],
   "source": [
    "# data['AgeInterval'] = pd.Series(['0-3', '3-6', '6-12', '12-24', '24-48', '48-120', '>120'], dtype='category')\n",
    "# data.loc[(data['Age'] >= 0) & (data['Age'] <= 3),'AgeInterval'] = '0-3'\n",
    "# data.loc[(data['Age'] > 3) & (data['Age'] <= 6),'AgeInterval'] = '3-6'\n",
    "# data.loc[(data['Age'] > 6) & (data['Age'] <= 12),'AgeInterval'] = '6-12'\n",
    "# data.loc[(data['Age'] > 12) & (data['Age'] <= 24),'AgeInterval'] = '12-24'\n",
    "# data.loc[(data['Age'] > 24) & (data['Age'] <= 48),'AgeInterval'] = '24-48'\n",
    "# data.loc[(data['Age'] > 48) & (data['Age'] <= 120),'AgeInterval'] = '48-120'\n",
    "# data.loc[data['Age'] > 120,'AgeInterval'] = '>120'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3c6cbe88ed3ef54f263c4f2dee62481ea3cb6bf"
   },
   "outputs": [],
   "source": [
    "# target = 'AdoptionSpeed'\n",
    "# categoricalFeatures = ['Type', 'Breed1', 'Gender', 'Color1', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "#                        'Health', 'AgeInterval']\n",
    "# numericalFeatures = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt']\n",
    "\n",
    "# (model, \n",
    "#  y_predicted, \n",
    "#  X_train, \n",
    "#  y_train, \n",
    "#  X_train_pool, \n",
    "#  X_test_pool) = trainCatboost(numericalFeatures, categoricalFeatures, target, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc88115a7382cc3338206d13dcfe6231c5e6696f"
   },
   "outputs": [],
   "source": [
    "# scores = calculateClassificationScores(y_test, y_predicted, model, X_test_pool)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f multiclass: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87fd2df420853181bf3d31a7623fc32a1d2bdeed"
   },
   "outputs": [],
   "source": [
    "# plotMostRelevantFeatures(X_train.dtypes.index, bestClf, X_train_pool, y_train.astype('int').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "942c35c3fbf322e8ea484067705391a88a160641"
   },
   "source": [
    "Train model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f62c15a865a6c1e1915ac9515d238947e29690bd"
   },
   "outputs": [],
   "source": [
    "# dataS = train[numericalFeatures + categorical + [target]].dropna()\n",
    "\n",
    "# X = dataS[numericalFeatures + categorical]\n",
    "# y = dataS[target]\n",
    "\n",
    "# prepare data for catboost\n",
    "# X_train = FeaturesData(\n",
    "#     num_feature_data=X[numericalFeatures].astype('float32').values,\n",
    "#     cat_feature_data=X[categorical].__array__(dtype=object)\n",
    "# )\n",
    "# y_train = y.astype('int').values\n",
    "\n",
    "# best model is with sentiment data {'depth': 6, 'iterations': 300, 'l2_leaf_reg': 12, 'learning_rate': 0.15}\n",
    "# bestClf = CatBoostClassifier(\n",
    "#             loss_function='MultiClass',\n",
    "#             verbose=False,\n",
    "#             depth=8,\n",
    "#             iterations=140,\n",
    "#             l2_leaf_reg=12,\n",
    "#             learning_rate=0.15,\n",
    "#             task_type='CPU',\n",
    "#             class_weights=[4, 1, 1, 1, 1]\n",
    "#         )\n",
    "        \n",
    "# bestClf.fit(X_train, y_train,logging_level='Silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0acb759c70b86431cb5c498bf36ccca99009ba2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transforming test as we transformed train\n",
    "# testClean = cleanTransformDataset(test)\n",
    "# testClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abe28c16ffb60ccb44d6fcc2a1644019233a7887"
   },
   "outputs": [],
   "source": [
    "def generateSubmissionCatboost(model, numericalFeatures, categoricalFeatures, test, fileName):\n",
    "    X = test[numericalFeatures + categoricalFeatures]\n",
    "    X = FeaturesData(\n",
    "            num_feature_data=X[numericalFeatures].astype('float32').values,\n",
    "            cat_feature_data=X[categoricalFeatures].__array__(dtype=object)\n",
    "        )\n",
    "    predictions = model.predict(X)\n",
    "    test['AdoptionSpeed'] = predictions\n",
    "    test.AdoptionSpeed = test['AdoptionSpeed'].map({0.0: '0', 1.0: '1', 2.0: '2', 3.0: '3', 4.0: '4'})\n",
    "    test[['PetID', 'AdoptionSpeed']].to_csv(fileName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82f8ab5298880812b2a98c82d7cbed4ccef17e11"
   },
   "outputs": [],
   "source": [
    "# generateSubmissionCatboost(bestClf, numericalFeatures, categorical, 'submission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2136a21100e80de2a253e0038aed75276994939"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd3e81a73d7c5a8c175b15271ce93ac6dab314d5"
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     pd.get_dummies(X),\n",
    "#     y.astype('int64'),\n",
    "#     test_size=0.25,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "# y_predicted = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "801b5f38217b45f30601b9a06bd758e9055a6273"
   },
   "outputs": [],
   "source": [
    "# scores = calculateClassificationScores(y_test, y_predicted, rf, X_test)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23a04e61b46cb66b55753c2e0fc7a4f698d98e5e"
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 400, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(6, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "433babe982a5cbf3592dce6074f0db73212017ce"
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "# rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35c92ae3ff62cb2dbdd15216f0b28e383333ecb4"
   },
   "outputs": [],
   "source": [
    "# y_predicted = rf_random.predict(X_test)\n",
    "# scores = calculateClassificationScores(y_test, y_predicted, rf_random, X_test)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cdfb8713a15634f14684596d6fc37815b678d66"
   },
   "outputs": [],
   "source": [
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f02760d64ca735ed0e6269458c1c89b3fb8b2a79"
   },
   "outputs": [],
   "source": [
    "# generateConfusionMatrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7827c6baf0c13853abc5fc4e44195c00502f3270"
   },
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3d57b6b718329cfd68467388de75c2db12bc395"
   },
   "outputs": [],
   "source": [
    "# ab = AdaBoostClassifier()\n",
    "# ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7711a701190d080ce0a216109fe5be3a05e8c019"
   },
   "outputs": [],
   "source": [
    "# y_predicted = ab.predict(X_test)\n",
    "# scores = calculateClassificationScores(y_test, y_predicted, ab, X_test)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f' % scores )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56d8e8b65814f49cad1548f324c55dea3a9328c6"
   },
   "source": [
    "GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54c3dabdd667f8b86a3f9f225a4b36d60d6b4faf"
   },
   "outputs": [],
   "source": [
    "# gb = GradientBoostingClassifier()\n",
    "# gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea39f4670b32810e97e4bc91fe4bb6cd06520a28"
   },
   "outputs": [],
   "source": [
    "# y_predicted = gb.predict(X_test)\n",
    "# scores = calculateClassificationScores(y_test, y_predicted, gb, X_test)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f' % scores )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4aeab4eaa1de2eabca93c31ef6173a46448c115"
   },
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2050a07778167e66f2ea0b6698d471463d273f4c"
   },
   "outputs": [],
   "source": [
    "# param = {'max_depth':8, 'eta':0.15, 'silent':1, 'objective':'multi:softmax' }\n",
    "# num_round = 140\n",
    "# xgbModel = xgb.XGBClassifier(max_depth=8, n_estimators=140, learning_rate=0.15)\n",
    "# xgbModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7f61e52c6bd256e67f21fc02eb094e95d245c7e"
   },
   "source": [
    "Voting ensembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ef101306604e5718a7e067a51ed350bcba2e6d4"
   },
   "outputs": [],
   "source": [
    "# vc = VotingClassifier(estimators=[('cb', bestClf), ('rf', rf_random), ('ab', ab), ('gb', gb) ], voting='hard')\n",
    "# vc = vc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82ab5cfc9bf072538afb5efd2ee859e7c6f43ded"
   },
   "outputs": [],
   "source": [
    "# y_predicted = vc.predict(X_test)\n",
    "# scores = calculateClassificationScores(y_test, y_predicted, vc, X_test)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f' % scores )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b59de516a5ad483c384ee5cfeae2b1090b4c837b"
   },
   "source": [
    "### XGBoost and OptimizeRounder with Kappa Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1e1a1ba779e211f9361915bef0294e023eaf221"
   },
   "outputs": [],
   "source": [
    "X_train_non_null = trainPrecomputed.fillna(-1)\n",
    "X_test_non_null = testPrecomputed.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b47056a90feb62387255cd941afacead99be14e5"
   },
   "outputs": [],
   "source": [
    "X_train_non_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f8d1a29b61e0303fe8aa4467add036a24f36b60"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4fc45bb6cf7d96b7069abf0c9ee5ef76e0eb84ee"
   },
   "outputs": [],
   "source": [
    "newFeatures = [\n",
    "    'metadata_topicality_max',\n",
    "    'metadata_topicality_mean',\n",
    "    'metadata_topicality_min',\n",
    "    'metadata_topicality_0_mean',\n",
    "    'metadata_topicality_0_max',\n",
    "    'metadata_topicality_0_min',\n",
    "    'L_metadata_0_cat_sum',\n",
    "    'L_metadata_0_dog_sum',\n",
    "    'L_metadata_any_cat_sum',\n",
    "    'L_metadata_any_dog_sum',\n",
    "    'blur_max',\n",
    "    'blur_sum',\n",
    "    'huMoments0',\n",
    "    'huMoments1',\n",
    "    'huMoments2',\n",
    "    'huMoments3',\n",
    "    'huMoments4',\n",
    "    'huMoments5',\n",
    "    'huMoments6',\n",
    "    'state_gdp',\n",
    "    'state_population',\n",
    "    'state_area',\n",
    "    'state_unemployment',\n",
    "    'state_birth_rate',\n",
    "    'L_Fee_Free',\n",
    "    'N_pets_total',\n",
    "    'L_NoPhoto',\n",
    "    'L_NoVideo',\n",
    "    'Log_Age',\n",
    "    'L_scoreneg',\n",
    "    'PetID'\n",
    "]\n",
    "X_train_non_null = X_train_non_null.join(train[newFeatures].set_index('PetID'), 'PetID')\n",
    "X_test_non_null = X_test_non_null.join(test[newFeatures].set_index('PetID'), 'PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d0affa8f9f83da0046771d6b13384f4a1dd1cc6"
   },
   "outputs": [],
   "source": [
    "to_drop_columns = ['PetID', 'Name', 'RescuerID']\n",
    "X_train_non_null = X_train_non_null.drop(to_drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42be72ab0900c56c9b7372a1007c07c1de72fcc2"
   },
   "outputs": [],
   "source": [
    "X_test_non_null = X_test_non_null.drop(to_drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45808dcdda36320872d47faf00a678c8efb3b6eb"
   },
   "outputs": [],
   "source": [
    "X_test_non_null = X_test_non_null.drop(['AdoptionSpeed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6887433cf464c86a3039b0a83b6c2ce71c70d33e"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "\n",
    "\n",
    "# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59840f0fd66e232bb9beb0ad58da2e0a737c6ae6"
   },
   "source": [
    "#### Optimze coefficients based on kappa loss. Final competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5c94c0acaee99942a812fabf2a0a329e9ac9d1c"
   },
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "    \n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return -cohen_kappa_score(y, preds, weights='quadratic')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "    \n",
    "    def predict(self, X, coef):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return preds\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb73ed2746b7e0b64b6a1c3bf9c928150013c7c3"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "xgb_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'eta': 0.0123,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'device': 'gpu',\n",
    "    'silent': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de7c1a8a824027edaf1c157329785b815a01712f"
   },
   "outputs": [],
   "source": [
    "def run_xgb(params, X_train, X_test):\n",
    "    n_splits = 10\n",
    "    verbose_eval = 1000\n",
    "    num_rounds = 60000\n",
    "    early_stop = 500\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n",
    "\n",
    "    oof_train = np.zeros((X_train.shape[0]))\n",
    "    oof_test = np.zeros((X_test.shape[0], n_splits))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n",
    "\n",
    "        X_tr = X_train.iloc[train_idx, :]\n",
    "        X_val = X_train.iloc[valid_idx, :]\n",
    "\n",
    "        y_tr = X_tr['AdoptionSpeed'].values\n",
    "        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "        y_val = X_val['AdoptionSpeed'].values\n",
    "        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n",
    "        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n",
    "                         early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n",
    "\n",
    "        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n",
    "        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        oof_train[valid_idx] = valid_pred\n",
    "        oof_test[:, i] = test_pred\n",
    "\n",
    "        i += 1\n",
    "    return model, oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbb86ebe45d148f1a5acb76c0f3213a5b696fa33"
   },
   "outputs": [],
   "source": [
    "model, oof_train, oof_test = run_xgb(xgb_params, X_train_non_null, X_test_non_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e153e22c1d1f26dc679983c6d281d6c2af564b15"
   },
   "outputs": [],
   "source": [
    "def plot_pred(pred):\n",
    "    sns.distplot(pred, kde=True, hist_kws={'range': [0, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9679d782af3ec324ecc1b80dc05eeb11e8e6ea4c"
   },
   "outputs": [],
   "source": [
    "plot_pred(oof_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6474a5c0615ffff34b985f1e5a3083ac0d9161b6"
   },
   "outputs": [],
   "source": [
    "plot_pred(oof_test.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d13af4d865ccb2610643bda427f90798ba80e6a7"
   },
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(oof_train, X_train_non_null['AdoptionSpeed'].values)\n",
    "coefficients = optR.coefficients()\n",
    "valid_pred = optR.predict(oof_train, coefficients)\n",
    "qwk = quadratic_weighted_kappa(X_train_non_null['AdoptionSpeed'].values, valid_pred)\n",
    "print(\"QWK = \", qwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ee865ba41c364d5f57e3f13bbb297442f76ef2a"
   },
   "outputs": [],
   "source": [
    "coefficients_ = coefficients.copy()\n",
    "coefficients_[0] = 1.66\n",
    "coefficients_[1] = 2.13\n",
    "coefficients_[3] = 2.85\n",
    "train_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\n",
    "print(f'train pred distribution: {Counter(train_predictions)}')\n",
    "test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)\n",
    "print(f'test pred distribution: {Counter(test_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f548d52d3910fe6e13bad59b3f821d14f83603a"
   },
   "outputs": [],
   "source": [
    "Counter(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7091ed0e047ca080aa51325141b895dac290b02"
   },
   "outputs": [],
   "source": [
    "Counter(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_non_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35d308a77591c1108906b239d929e74650b37550"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PetID': X_test_non_null['PetID'].values, 'AdoptionSpeed': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c77e1ab1bf63d1158c6cca069286fbb1e0f76d40"
   },
   "source": [
    "### Catboost with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53fe1ecd35e5314263b85216cbf128d4b8f50c9c"
   },
   "outputs": [],
   "source": [
    "# X_train_cb = X_train_non_null.copy()\n",
    "\n",
    "\n",
    "# target = 'AdoptionSpeed'\n",
    "# categoricalFeatures = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n",
    "#                        'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n",
    "#                        'Health', 'State', 'AdoptionSpeed']\n",
    "\n",
    "# X_train_cb[categoricalFeatures] = X_train_cb[categoricalFeatures].astype('category')\n",
    "\n",
    "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "# numericalFeatures = list(X_train_cb.select_dtypes(include=numerics).columns)\n",
    "\n",
    "# X_train_cb[numericalFeatures] = X_train_cb[numericalFeatures].fillna(-1)\n",
    "\n",
    "# categoricalFeaturesTest = list(set(categoricalFeatures) - set([target]))\n",
    "# X_test_cb = X_test_non_null.copy()\n",
    "# X_test_cb[categoricalFeaturesTest] = X_test_cb[categoricalFeaturesTest].astype('category')\n",
    "# X_test_cb[numericalFeatures] = X_test_cb[numericalFeatures].fillna(-1)\n",
    "\n",
    "# # cleanTransformDataset(X_train_cb, categoricalFeatures)\n",
    "\n",
    "# (model, \n",
    "#  y_predicted, \n",
    "#  X_train, \n",
    "#  y_train, \n",
    "#  X_train_pool, \n",
    "#  X_test_pool,\n",
    "#  y_test) = trainCatboost(numericalFeatures, categoricalFeatures, target, X_train_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = calculateClassificationScores(y_test, y_predicted, model, X_test_pool)\n",
    "# print('accuracy: %f f1: %f precision: %f recall: %f multiclass: %f' % scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateConfusionMatrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotMostRelevantFeatures(X_train.dtypes.index, model, X_train_pool, y_train.astype('int').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_train_cb[numericalFeatures + categoricalFeatures]\n",
    "# y = X_train_cb[target]\n",
    "\n",
    "# # prepare data for catboost\n",
    "# X_train = FeaturesData(\n",
    "#     num_feature_data=X[numericalFeatures].astype('float32').values,\n",
    "#     cat_feature_data=X[categoricalFeatures].__array__(dtype=object)\n",
    "# )\n",
    "# y_train = y.astype('int').values\n",
    "\n",
    "# # best model is with sentiment data {'depth': 6, 'iterations': 300, 'l2_leaf_reg': 12, 'learning_rate': 0.15}\n",
    "# bestClf = CatBoostClassifier(\n",
    "#             loss_function='MultiClass',\n",
    "#             verbose=False,\n",
    "#             depth=8,\n",
    "#             iterations=140,\n",
    "#             l2_leaf_reg=12,\n",
    "#             learning_rate=0.15,\n",
    "#             task_type='CPU',\n",
    "#             class_weights=[4, 1, 1, 1, 1]\n",
    "#         )\n",
    "        \n",
    "# bestClf.fit(X_train, y_train,logging_level='Silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateSubmissionCatboost(bestClf, numericalFeatures, categoricalFeatures, X_test_cb, 'submission')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
